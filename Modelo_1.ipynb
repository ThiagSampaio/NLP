{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    },
    "colab": {
      "name": "Modelo_1.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ThiagSampaio/NLP/blob/main/Modelo_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f3trIvXswN5G"
      },
      "source": [
        "<h1> Modelo de regress√£o _logistica </h1>\n",
        "\n",
        "Antes tudo, rode as tres linhas abaixo"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9wp00J-Nwcj6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bde435cc-3984-452c-843e-3415daa2fa23"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4e7LckdWlafs",
        "outputId": "9ea75f8b-f51e-4cf6-e7fc-beb628232180"
      },
      "source": [
        "%cd drive/MyDrive/Analise\\ sentimento"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive/Analise sentimento\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t23-hUE5xMUU"
      },
      "source": [
        "<h3>1 . Importando bibliotecas </h3>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qw7nxY9RxbH2"
      },
      "source": [
        "#importando bibliotecas prontas\n",
        "import re\n",
        "import string\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import PorterStemmer\n",
        "from nltk.tokenize import TweetTokenizer\n",
        "\n",
        "from getting_data import *\n",
        "from Processamento import *\n",
        "from Processamento_treinamento import *\n",
        "from nomes_brasileiros import *\n",
        "from Processamento_expressoes import *\n",
        "from getting_data import TwitterClient"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gd9GWVdzyI-d"
      },
      "source": [
        "<h3>2 . Importando dados importantes</h3>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VSJlDqv8x98a",
        "outputId": "2bf8c744-3ee5-4a46-b6d8-5c6d08afef64"
      },
      "source": [
        "nltk.download('stopwords')\n",
        "\n",
        "#importando lista_nomes e presidentes brasileiros. \n",
        "lista_presidentes = [\"jos√© sarney\", \"sarney\", \"fernando Collor\", \"collor\", \"itamar Franco\",\n",
        "                     \"fernando henrique cardoso\", \"luiz in√°cio lula da silva\", \"lula\", \"lulinha\",\n",
        "                     \"dilma Rouseff\", \"dilm√£o\", \"dilm√£e\", \"michel temer\", \"vampiro\", \"jair bolsonaro\",\n",
        "                     \"birolibo\", \"bozo\", \"birobiro\", \"bozonaro\", \"bolsonaro\"]\n",
        "lista_nome = lista_nomes() #pct nomes brasileiros\n",
        "lista_nome = lista_nome + lista_presidentes\n",
        "\n",
        "#importando lista_expressoes\n",
        "lista_expressoes_positivas, lista_expressoes_negativas = lista_expressoes()\n",
        "\n",
        "#adicionando termos negativos\n",
        "termos_negativos = [\"genocida\", \"suicidio\", \"suicidar\", \"merda\", \"bosta\", \"assassino\", \"estuprador\", \"fdp\", \"racista\", \"√≥dio\"]\n",
        "lista_expressoes_negativas = lista_expressoes_negativas + termos_negativos\n",
        "\n",
        "#pegando dados kaggle sobre tweets positivos e nagativos\n",
        "lista_positiva,lista_negativa = tratamento()\n",
        "\n",
        "#Somando todos os termos\n",
        "lista_positiva = lista_positiva + lista_expressoes_positivas\n",
        "lista_negativa = lista_negativa + lista_expressoes_negativas\n",
        "\n",
        "lista_completa  = lista_positiva + lista_negativa\n",
        "\n",
        "#Criando vetores \n",
        "labels = np.append(np.ones((len(lista_positiva))), np.zeros((len(lista_negativa))))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZmKfdJ5l1qCW"
      },
      "source": [
        "<h3>3. Fun√ß√µes </h3>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1qA_dxmUQu6g"
      },
      "source": [
        "import string\n",
        "def process_tweet(tweet, lista_names = lista_nome):\n",
        "    \"\"\"Fun√ß√£o de processamento de um tweet.\n",
        "    Input:\n",
        "        tweet: a string contendo o tweet\n",
        "    Output:\n",
        "        tweets_clean: uma lista de palavras contendo o tweet processado\n",
        "\n",
        "    \"\"\"\n",
        "    #pegando lista de palavras stopwords\n",
        "    stopwords_portuguese = stopwords.words('portuguese')\n",
        " \n",
        "    # remove tickers do mercado de a√ß√µes como $ GE\n",
        "    tweet = re.sub(r'\\$\\w*', '', tweet)\n",
        "    \n",
        "    # remove o texto retweetado no estilo antigo \"RT\"\n",
        "    tweet = re.sub(r'^RT[\\s]+', '', tweet)\n",
        "    \n",
        "    # remove hyperlinks\n",
        "    tweet = re.sub(r'https?:\\/\\/.*[\\r\\n]*', '', tweet)\n",
        "    \n",
        "    # remove hashtags\n",
        "    tweet = re.sub(r'#', '', tweet)\n",
        "    \n",
        "    # remove os @\n",
        "    tweet = re.sub(r'@', '', tweet)\n",
        "\n",
        "    '''\n",
        "    # remove os emojis\n",
        "    padrao_emoji = re.compile(\"[\"\n",
        "                            u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
        "                            u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
        "                            u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
        "                            u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
        "                            u\"\\U00002500-\\U00002BEF\"  # chinese char\n",
        "                            u\"\\U00002702-\\U000027B0\"\n",
        "                            u\"\\U00002702-\\U000027B0\"\n",
        "                            u\"\\U000024C2-\\U0001F251\"\n",
        "                            u\"\\U0001f926-\\U0001f937\"\n",
        "                            u\"\\U00010000-\\U0010ffff\"\n",
        "                            u\"\\u2640-\\u2642\"\n",
        "                            u\"\\u2600-\\u2B55\"\n",
        "                            u\"\\u200d\"\n",
        "                            u\"\\u23cf\"\n",
        "                            u\"\\u23e9\"\n",
        "                            u\"\\u231a\"\n",
        "                            u\"\\ufe0f\"  # dingbats\n",
        "                            u\"\\u3030\"\n",
        "                            \"]+\", flags=re.UNICODE)\n",
        "    tweet = re.sub(padrao_emoji, '', tweet)\n",
        "   '''\n",
        "    \n",
        "    # tokenize tweets\n",
        "    tokenizer = TweetTokenizer(preserve_case=False, strip_handles=True,\n",
        "                               reduce_len=True)\n",
        "    tweet_tokens = tokenizer.tokenize(tweet)\n",
        "\n",
        "    tweets_clean = []\n",
        "    \n",
        "    for word in tweet_tokens:\n",
        "        if (word not in stopwords_portuguese and  # remove stopwords\n",
        "                word not in string.punctuation and # remove pontua√ß√£o\n",
        "                    word not in lista_names):  # remove nomes\n",
        "            \n",
        "            tweets_clean.append(word)\n",
        "    \n",
        "    return tweets_clean"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nDSi4SSaQu6h",
        "outputId": "c222abc1-ade8-4af1-a6f6-5ea81270898d"
      },
      "source": [
        "# teste da fun√ß√£o process_tweet\n",
        "tweet = \"merda üòÇ Bolsonaro!!!\"\n",
        "frase = process_tweet(tweet)\n",
        "print (frase)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['merda', 'üòÇ']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8JDz5WsdQu6i"
      },
      "source": [
        "def build_freqs(tweets, ys, lista_names = lista_nome):\n",
        "    \"\"\"Crie frequ√™ncias.\n",
        "    Entrada:\n",
        "        tweets: uma lista de tweets\n",
        "        ys: uma matriz m x 1 com o r√≥tulo de sentimento de cada tweet\n",
        "            (0 ou 1)\n",
        "    Sa√≠da:\n",
        "        freqs: um dicion√°rio que mapeia cada par (palavra, sentimento) para seu\n",
        "        frequ√™ncia\n",
        "    \"\"\"\n",
        "    # Converta o array np em lista, pois o zip precisa de um iter√°vel.\n",
        "    # O aperto √© necess√°rio ou a lista termina com um elemento.\n",
        "    # Observe tamb√©m que este √© apenas um NOP se ys j√° for uma lista.\n",
        "    yslist = np.squeeze(ys).tolist()\n",
        "\n",
        "    freqs = {}\n",
        "    for y, tweet in zip(yslist, tweets):\n",
        "        for word in process_tweet(tweet,lista_names):\n",
        "            pair = (word, y)\n",
        "            if pair in freqs:\n",
        "                freqs[pair] += 1\n",
        "            else:\n",
        "                freqs[pair] = 1\n",
        "\n",
        "    return freqs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uLjmFnNjQu6l"
      },
      "source": [
        "from math import *"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YDDFPmvcQu6l",
        "outputId": "ca6eeeed-11a3-40f4-ba65-29c86a908929"
      },
      "source": [
        "print(len(lista_positiva))\n",
        "print(len(lista_negativa))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "248276\n",
            "313952\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QJyJwX1DK_iQ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        },
        "outputId": "35194fdd-8fc7-41cd-8133-5ad398ac70c5"
      },
      "source": [
        "'''\n",
        "import random\n",
        "for i in range(1,65675):\n",
        "  lista_negativa.remove(random.choice(lista_negativa))\n",
        "'''  "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-36-e15346c67c44>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mrandom\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m65675\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m   \u001b[0mlista_negativa\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mremove\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchoice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlista_negativa\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v8dPnFvWQu6l"
      },
      "source": [
        "train_pos = lista_positiva\n",
        "train_neg = lista_negativa"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G-_MGW7QQu6m"
      },
      "source": [
        "train_x = train_pos + train_neg "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J7RBn7lYQu6m"
      },
      "source": [
        "train_y = np.append(np.ones((len(train_pos), 1)), np.zeros((len(train_neg), 1)), axis=0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pn-jdM1pQu6m"
      },
      "source": [
        "freqs = build_freqs(train_x, train_y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lkAO3jet-ryH"
      },
      "source": [
        "import pickle\n",
        "with open('freqs.json', 'wb') as fp:\n",
        "    pickle.dump(freqs, fp)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7diRhJHsQu6n"
      },
      "source": [
        "def sigmoid(z): \n",
        "  '''\n",
        "    Entrada:\n",
        "        z: √© a entrada (pode ser um escalar ou uma matriz)\n",
        "    Sa√≠da:\n",
        "        h: o sigm√≥ide de z\n",
        "    '''\n",
        "    \n",
        "    h = 1 / (1 + np.exp(-z))\n",
        "  \n",
        "    return h"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yqP8xi07Qu6n"
      },
      "source": [
        "def gradientDescent(x, y, theta, alpha, num_iters):\n",
        "\n",
        "    m = x.shape[0]\n",
        "    \n",
        "    for i in range(0, num_iters):\n",
        "       \n",
        "        z = np.dot(x, theta)\n",
        "      \n",
        "        h = sigmoid(z)\n",
        "        \n",
        "        J = (-1/m) * (np.dot(y.T, np.log(h)) + np.dot((1 - y).T,np.log(1-h)))\n",
        "\n",
        "        \n",
        "        theta = theta - (alpha/m) * (np.dot(x.T,(h - y)))\n",
        "        \n",
        "  \n",
        "    J = float(J)\n",
        "    return J, theta"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y3m_Wzs4Qu6n"
      },
      "source": [
        "def extract_features(tweet, freqs):\n",
        "\n",
        "   \n",
        "    word_l = process_tweet(tweet)\n",
        "    \n",
        "   \n",
        "    x = np.zeros((1, 3)) \n",
        "    \n",
        "    x[0,0] = 1 \n",
        "    \n",
        "\n",
        "    for word in word_l:\n",
        "        \n",
        "\n",
        "        x[0,1] += freqs.get((word, 1.0), 0)\n",
        "        \n",
        "        x[0,2] += freqs.get((word, 0.0),0)\n",
        "        \n",
        "    assert(x.shape == (1, 3))\n",
        "    return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "locSI6buQu6o",
        "outputId": "8fd0a353-371f-4138-b0e0-a9da2b93aa39"
      },
      "source": [
        "X = np.zeros((len(train_x), 3))\n",
        "for i in range(len(train_x)):\n",
        "    X[i, :]= extract_features(train_x[i], freqs)\n",
        "\n",
        "Y = train_y\n",
        "\n",
        "# Apply gradient descent\n",
        "J, theta = gradientDescent(X, Y, np.zeros((3, 1)), 1e-9, 1500)\n",
        "print(f\"The cost after training is {J:.8f}.\")\n",
        "print(f\"The resulting vector of weights is {[round(t, 8) for t in np.squeeze(theta)]}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:27: RuntimeWarning: divide by zero encountered in log\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "The cost after training is nan.\n",
            "The resulting vector of weights is [0.0, 0.00012059, -7.062e-05]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wBFrMFFpCSJf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9e9b7594-da83-4713-af03-9155b6d6a7ee"
      },
      "source": [
        "theta"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 4.49412614e-09],\n",
              "       [ 1.20599068e-04],\n",
              "       [-7.05937233e-05]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2C8uKk2G_Z4p"
      },
      "source": [
        "import pickle\n",
        "with open('theta.json', 'wb') as fp:\n",
        "    pickle.dump(theta, fp)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OzO28ZWPQu6o"
      },
      "source": [
        "def predict_tweet(tweet, freqs, theta):\n",
        "\n",
        "    x = extract_features(tweet,freqs)\n",
        "    \n",
        "\n",
        "    y_pred = sigmoid(np.dot(x,theta))\n",
        "    \n",
        "  \n",
        "    \n",
        "    return y_pred"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BJjwDtv3LvH5"
      },
      "source": [
        "#importando tweets recentes\n",
        "twitter = []\n",
        "api = TwitterClient()\n",
        "tweets = api.get_tweets(query = 'bolsonaro', count = 50)\n",
        "tweets = dict_to_list(tweets)\n",
        "\n",
        "lista_tweet_positiva = []\n",
        "lista_tweet_negativa = []\n",
        "cont_neg = 0\n",
        "cont_pos = 0\n",
        "for i in tweets:\n",
        "\n",
        "  tweet_tratado = process_tweet(i, lista_names = lista_nome)\n",
        "  stringu = ' '.join([str(item) for item in tweet_tratado])\n",
        "  #print(stringu)\n",
        "  y_hat = predict_tweet(stringu, freqs, theta)\n",
        "  if y_hat > 0.75:\n",
        "    #print('Positive sentiment')\n",
        "    cont_pos += 1\n",
        "    lista_tweet_positiva.append(i)\n",
        "  else: \n",
        "    #print('Negative sentiment')\n",
        "    cont_neg += 1\n",
        "    lista_tweet_negativa.append(i)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4UE3nc5lQu6q",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3a02ba2c-2eba-4fb3-9483-6824503bce4e"
      },
      "source": [
        "print(len(lista_tweet_negativa))\n",
        "print(len(lista_tweet_positiva))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "43\n",
            "6\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cyu6PztgNabr",
        "outputId": "5e937d55-b00c-4012-b7ca-b0092cbf9349"
      },
      "source": [
        "lista_tweet_positiva"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Missa de s√©timo dia do governo Bolsonaro √© marcada para sexta que vem https://t.co/iWrBFNzOHc',\n",
              " 'RT @manugavassi: √â √≥bvio mas sempre bom deixar claro e renovar meus votos (desde sempre) de: FORA BOLSONARO!',\n",
              " 'RT @De_Pablicia: O DIA N PODERIA COME√áAR MELHOR \\nBOLSONARO CAIU https://t.co/JnSniO1vb8',\n",
              " 'RT @_anandamiranda: RESUM√ÉO DA CPI:\\n\\n1. A Pfizer n√£o foi comprada n√£o por ser cara, mas sim para favorecer a Covaxin\\n\\n2. A Covaxin n√£o era‚Ä¶',\n",
              " 'RT @samiabomfim: AGORA! Protesto em S√£o Paulo contra Jair Bolsonaro. A mobiliza√ß√£o pelo impeachment tem que ser permanente e n√£o pode esper‚Ä¶',\n",
              " 'RT @cris_mx31: Bom dia!! O dia j√° come√ßa com os trend topics perfeitos!! √â hoje!!\\nBOLSONARO CAIU\\nACABOU BOLSONARO https://t.co/dYn9R4Kli9']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 89
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hizF-FLcReOC"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}